{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## non-negative matrix factorization (NMF) based topic modeling\n",
    "This notebook presents the NMF approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "#from gensim.utils import simple_preprocess\n",
    "#from gensim.models import CoherenceModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "### load NMF utility functions\n",
    "from nmf_util import *\n",
    "### load coherence score\n",
    "import gensim.downloader as api\n",
    "from coherence_score import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data from Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### json load the dataset\n",
    "## 20news-18828.json\n",
    "with open('../cleaned_data/yahoo_answers_csv.json', 'r') as jf:\n",
    "    cleaned_data = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_sample = cleaned_data[-60000:]\n",
    "with open('../cleaned_data/yahoo_sample.json', 'w') as jf:\n",
    "    json.dump(yahoo_sample, jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### split data into 'sentence' and 'label'\n",
    "sentences = [it['sentence'] for it in cleaned_data]\n",
    "labels = [it['label'] for it in cleaned_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1', '10', '2', '3', '4', '5', '6', '7', '8', '9'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_glove = api.load(\"glove-twitter-100\")   ## load pretrained glove embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Count Vectors as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert the corpora to Count vectors\n",
    "count = CountVectorizer(max_df=.95, min_df=10, max_features=5000)\n",
    "x_count = count.fit_transform(sentences)\n",
    "## convert to matrix --- feature-document matrix\n",
    "count_mat = x_count.toarray().T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## features\n",
    "features = count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 18828)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NMF methods for topic modeling\n",
    "k = 10     ## the number of topics -- tune it for better result\n",
    "max_iter = 10  ## maximum number of iterations\n",
    "W,H,err=gaussian_method(count_mat, k, max_iter)  ## will return factor matrices: W, H and root mean squared error\n",
    "#res1=poisson_method(count_mat.T, k, max_iter=5)\n",
    "#res2=exponential_method(count_mat.T, k, max_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract top keywords, each topic presents 20 keywords\n",
    "dic0 = top_keywords(W, features, num=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['maxaxaxaxaxaxaxaxaxaxaxaxaxaxax',\n",
       "  '14',\n",
       "  'part',\n",
       "  'end',\n",
       "  '12',\n",
       "  '11',\n",
       "  '13',\n",
       "  'keywords',\n",
       "  '10',\n",
       "  'ha',\n",
       "  'one',\n",
       "  'make',\n",
       "  'key',\n",
       "  'article',\n",
       "  'use',\n",
       "  'writes',\n",
       "  'may',\n",
       "  'wire',\n",
       "  're',\n",
       "  'would'],\n",
       " 1: ['wa',\n",
       "  'one',\n",
       "  'people',\n",
       "  'would',\n",
       "  'said',\n",
       "  'say',\n",
       "  'know',\n",
       "  'like',\n",
       "  'dont',\n",
       "  'time',\n",
       "  'armenian',\n",
       "  'even',\n",
       "  'ha',\n",
       "  'didnt',\n",
       "  'could',\n",
       "  'see',\n",
       "  'go',\n",
       "  'get',\n",
       "  'well',\n",
       "  'way'],\n",
       " 2: ['system',\n",
       "  'image',\n",
       "  'file',\n",
       "  'available',\n",
       "  'use',\n",
       "  'window',\n",
       "  'program',\n",
       "  'also',\n",
       "  'software',\n",
       "  'version',\n",
       "  'data',\n",
       "  'ftp',\n",
       "  'server',\n",
       "  'get',\n",
       "  'user',\n",
       "  'graphic',\n",
       "  'application',\n",
       "  'display',\n",
       "  'support',\n",
       "  'format'],\n",
       " 3: ['db',\n",
       "  'byte',\n",
       "  'bit',\n",
       "  'push',\n",
       "  'one',\n",
       "  'pop',\n",
       "  'si',\n",
       "  'inc',\n",
       "  'al',\n",
       "  'loop',\n",
       "  'offset',\n",
       "  'call',\n",
       "  'higher',\n",
       "  'lower',\n",
       "  'particle',\n",
       "  'gas',\n",
       "  'data',\n",
       "  'west',\n",
       "  'east',\n",
       "  'left'],\n",
       " 4: ['jpeg',\n",
       "  'image',\n",
       "  'file',\n",
       "  'gif',\n",
       "  'format',\n",
       "  'color',\n",
       "  'quality',\n",
       "  'viewer',\n",
       "  'free',\n",
       "  'version',\n",
       "  'see',\n",
       "  'display',\n",
       "  'setting',\n",
       "  'dont',\n",
       "  'conversion',\n",
       "  'convert',\n",
       "  'shareware',\n",
       "  'pixel',\n",
       "  'quicktime',\n",
       "  'simtel20'],\n",
       " 5: ['25',\n",
       "  '10',\n",
       "  '14',\n",
       "  '16',\n",
       "  '12',\n",
       "  '15',\n",
       "  '11',\n",
       "  '13',\n",
       "  '20',\n",
       "  '18',\n",
       "  '19',\n",
       "  '17',\n",
       "  '21',\n",
       "  '23',\n",
       "  '30',\n",
       "  '24',\n",
       "  '27',\n",
       "  '26',\n",
       "  '22',\n",
       "  'la'],\n",
       " 6: ['file',\n",
       "  'entry',\n",
       "  'gun',\n",
       "  'program',\n",
       "  'section',\n",
       "  'output',\n",
       "  'char',\n",
       "  'line',\n",
       "  'rule',\n",
       "  'firearm',\n",
       "  'control',\n",
       "  'contest',\n",
       "  'state',\n",
       "  'bill',\n",
       "  'use',\n",
       "  'build',\n",
       "  'remark',\n",
       "  'stream',\n",
       "  'name',\n",
       "  'number'],\n",
       " 7: ['god',\n",
       "  'jehovah',\n",
       "  'lord',\n",
       "  'jesus',\n",
       "  'christ',\n",
       "  'father',\n",
       "  'son',\n",
       "  'christian',\n",
       "  'bible',\n",
       "  'unto',\n",
       "  'one',\n",
       "  'shall',\n",
       "  'verse',\n",
       "  'say',\n",
       "  'spirit',\n",
       "  'mormon',\n",
       "  'man',\n",
       "  'word',\n",
       "  'also',\n",
       "  'true'],\n",
       " 8: ['mr',\n",
       "  'president',\n",
       "  'think',\n",
       "  'ha',\n",
       "  'dont',\n",
       "  'know',\n",
       "  'going',\n",
       "  'myers',\n",
       "  'would',\n",
       "  'well',\n",
       "  'question',\n",
       "  'thats',\n",
       "  'decision',\n",
       "  'made',\n",
       "  'believe',\n",
       "  'package',\n",
       "  'job',\n",
       "  'doe',\n",
       "  'make',\n",
       "  'mean'],\n",
       " 9: ['ha',\n",
       "  'new',\n",
       "  'space',\n",
       "  'year',\n",
       "  'planet',\n",
       "  'team',\n",
       "  'first',\n",
       "  'earth',\n",
       "  'information',\n",
       "  '1993',\n",
       "  'hockey',\n",
       "  'game',\n",
       "  'also',\n",
       "  'launch',\n",
       "  'center',\n",
       "  'league',\n",
       "  'satellite',\n",
       "  'national',\n",
       "  'two',\n",
       "  'state']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the coherence score of each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute the coherence score for each topic\n",
    "coherence_vec = []\n",
    "for i in range(W.shape[1]):  \n",
    "    coherence_vec.append(coherence(dic0[i], model_glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55294484"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(coherence_vec)   ## the mean coherence score of all topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use TFIDF vectors as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(max_df=.95, min_df=10, max_features=5000)\n",
    "x_tfidf = tfidf_vect.fit_transform(sentences)\n",
    "## covert to matrix\n",
    "tfidf_mat = x_tfidf.toarray().T\n",
    "#print(tfidf_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NMF methods for matrix factorization\n",
    "k, max_iter = 10,10\n",
    "W_tfidf,H_tfidf,err=gaussian_method(tfidf_mat, k, max_iter)\n",
    "#tfidf_res1=poisson_method(tfidf_mat, k, max_iter=5)\n",
    "#tfidf_res2=exponential_method(tfidf_mat, k, max_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_tfidf.shape\n",
    "features_tfidf = tfidf_vect.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_tfidf = top_keywords(W_tfidf, features_tfidf, num=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute the coherence score for each topic\n",
    "coherence_vec = []\n",
    "for i in range(W.shape[1]):  \n",
    "    coherence_vec.append(coherence(dic_tfidf[i], model_glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47842345"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(coherence_vec)  ## the mean coherence score of all topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(labels)))   ## indices of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split data into train and test\n",
    "ind_train, ind_test, y_train, y_test = train_test_split(\n",
    "    indices, labels, test_size=0.2, random_state=2021, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train/test datasets\n",
    "x_train, x_test = H[:, ind_train],H[:, ind_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 15062), (10, 3766), 15062, 3766)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,x_test.shape,len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## encode labels to integers\n",
    "Encoder = LabelEncoder()\n",
    "Y_train = Encoder.fit_transform(y_train)\n",
    "Y_test = Encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 13, 11, ...,  9,  0,  1], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.222     0.013     0.024       160\n",
      "           1      0.733     0.056     0.105       195\n",
      "           2      0.337     0.178     0.233       197\n",
      "           3      0.247     0.184     0.211       196\n",
      "           4      0.000     0.000     0.000       192\n",
      "           5      0.444     0.061     0.108       196\n",
      "           6      0.102     0.840     0.182       194\n",
      "           7      0.080     0.056     0.065       198\n",
      "           8      0.103     0.543     0.173       199\n",
      "           9      0.243     0.085     0.126       199\n",
      "          10      0.667     0.060     0.110       200\n",
      "          11      0.267     0.061     0.099       198\n",
      "          12      0.083     0.005     0.010       196\n",
      "          13      0.048     0.010     0.017       198\n",
      "          14      0.339     0.193     0.246       197\n",
      "          15      0.536     0.590     0.562       200\n",
      "          16      0.360     0.170     0.231       182\n",
      "          17      0.302     0.101     0.151       188\n",
      "          18      0.429     0.039     0.071       155\n",
      "          19      0.000     0.000     0.000       126\n",
      "\n",
      "    accuracy                          0.168      3766\n",
      "   macro avg      0.277     0.162     0.136      3766\n",
      "weighted avg      0.281     0.168     0.141      3766\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiji\\Anaconda3\\envs\\topic_modeling\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shiji\\Anaconda3\\envs\\topic_modeling\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shiji\\Anaconda3\\envs\\topic_modeling\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Classifier - Algorithm - SVM -- linear kernel\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1., kernel='linear', degree=3, gamma='auto', random_state=82)#, class_weight='balanced')\n",
    "SVM.fit(x_train.T, Y_train)# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(x_test.T) # make predictions\n",
    "print(classification_report(Y_test, predictions_SVM, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.182     0.006     0.012       639\n",
      "           1      0.719     0.059     0.109       778\n",
      "           2      0.362     0.221     0.274       788\n",
      "           3      0.196     0.155     0.173       786\n",
      "           4      0.000     0.000     0.000       769\n",
      "           5      0.412     0.060     0.105       784\n",
      "           6      0.099     0.815     0.176       778\n",
      "           7      0.088     0.052     0.065       792\n",
      "           8      0.094     0.491     0.158       795\n",
      "           9      0.185     0.060     0.091       795\n",
      "          10      0.505     0.063     0.111       799\n",
      "          11      0.250     0.061     0.097       793\n",
      "          12      0.220     0.017     0.031       785\n",
      "          13      0.093     0.019     0.031       792\n",
      "          14      0.353     0.180     0.238       790\n",
      "          15      0.516     0.555     0.535       797\n",
      "          16      0.358     0.165     0.226       728\n",
      "          17      0.383     0.160     0.225       752\n",
      "          18      0.453     0.039     0.071       620\n",
      "          19      0.000     0.000     0.000       502\n",
      "\n",
      "    accuracy                          0.165     15062\n",
      "   macro avg      0.273     0.159     0.137     15062\n",
      "weighted avg      0.277     0.165     0.141     15062\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiji\\Anaconda3\\envs\\topic_modeling\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shiji\\Anaconda3\\envs\\topic_modeling\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shiji\\Anaconda3\\envs\\topic_modeling\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "### fitting on training dataset\n",
    "predictions_train = SVM.predict(x_train.T) # predict training examples\n",
    "print(classification_report(Y_train, predictions_train, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
